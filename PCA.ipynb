{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3124292c",
   "metadata": {},
   "source": [
    "\n",
    "# üåü Data Mining Project: Principal Component Analysis (PCA) on the Adult Dataset üåü\n",
    "\n",
    "Welcome to your Data Mining project! In this comprehensive exercise, you'll apply **Principal Component Analysis (PCA)** to analyze the Adult dataset. PCA helps reduce dimensionality, simplify visualization, and highlight underlying patterns in data.\n",
    "\n",
    "üéØ **Project Goals:**\n",
    "\n",
    "By completing this project, you'll learn how to:\n",
    "\n",
    "- Import essential Python libraries for data analysis.\n",
    "- Load, clean, and preprocess real-world data.\n",
    "- Perform Exploratory Data Analysis (EDA) to uncover data insights.\n",
    "- Encode categorical variables and normalize numerical features.\n",
    "- Implement PCA manually to better understand the algorithm.\n",
    "- Visualize PCA results clearly and interpret principal components.\n",
    "\n",
    "Let's start your journey into PCA analysis! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4ef86",
   "metadata": {},
   "source": [
    "\n",
    "## üìö Step 1: Importing Essential Libraries\n",
    "\n",
    "In this initial step, you will import all necessary Python libraries required for data manipulation, visualization, and preprocessing.\n",
    "\n",
    "Run the provided code to import the following libraries:\n",
    "\n",
    "- **pandas**: For data handling and manipulation.\n",
    "- **numpy**: For numerical computations.\n",
    "- **matplotlib** and **seaborn**: For creating insightful visualizations.\n",
    "- **StandardScaler and OneHotEncoder from sklearn**: For scaling numerical features and encoding categorical data.\n",
    "\n",
    "Execute the cell below to load these libraries into your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395b457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d0334",
   "metadata": {},
   "source": [
    "\n",
    "## üìÇ Step 2: Loading and Exploring the Dataset\n",
    "\n",
    "In this step, load the dataset named `adult.csv` into a DataFrame using pandas. Once loaded, briefly inspect the dataset by displaying the first five rows.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Load your data using `pd.read_csv()`.\n",
    "- Use the `.head()` method to preview the data structure.\n",
    "\n",
    "**Example Code:**\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('your-dataset.csv')\n",
    "df.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7cd0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330ad09",
   "metadata": {},
   "source": [
    "\n",
    "## üßπ Step 3: Cleaning and Preprocessing the Dataset\n",
    "\n",
    "Data in the real world is often incomplete or messy. Your task here is to clean the dataset by:\n",
    "\n",
    "- Replacing '?' entries (unknown values) with `NaN`.\n",
    "- Removing all rows containing any `NaN` values.\n",
    "- Resetting the DataFrame's index to ensure it's clean and orderly.\n",
    "- Checking the data type and completeness of each feature with `.info()`.\n",
    "\n",
    "**Useful Methods:**\n",
    "\n",
    "- `.replace()` for replacing values.\n",
    "- `.dropna()` for removing missing values.\n",
    "- `.reset_index()` to reorder indices.\n",
    "\n",
    "Complete the tasks in the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12aa166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bded808",
   "metadata": {},
   "source": [
    "\n",
    "## üìä Step 4: Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA helps you understand your data and discover insights before modeling. Complete the following visual analyses:\n",
    "\n",
    "- **Scatter Plot:** Examine the relationship between `age` and `hours-per-week`, distinguishing individuals by `income`.\n",
    "- **Histogram:** Analyze the distribution of the `age` variable to understand its frequency distribution.\n",
    "- **Box Plot:** Identify potential outliers in the `age` data.\n",
    "- **Pair Plot:** Explore relationships and interactions among `age`, `educational-num`, and `hours-per-week` with respect to `income`.\n",
    "\n",
    "**Recommended Functions:**\n",
    "\n",
    "- `sns.scatterplot()` for scatter plots.\n",
    "- `sns.histplot()` for histograms.\n",
    "- `sns.boxplot()` to detect outliers visually.\n",
    "- `sns.pairplot()` to study pairwise relationships between multiple features.\n",
    "\n",
    "Perform these visualizations clearly and interpret your observations briefly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6930482",
   "metadata": {},
   "source": [
    "\n",
    "## ‚öôÔ∏è Step 5: Encoding Categorical Data & Normalizing Numerical Features\n",
    "\n",
    "Before PCA can be applied, it's important to convert categorical data into numerical form and scale numerical features:\n",
    "\n",
    "- Apply **One-Hot Encoding** to transform categorical variables (`workclass`, `education`, `gender`, etc.) using `pd.get_dummies()`.\n",
    "- Normalize numerical variables (`age`, `fnlwgt`, `hours-per-week`, etc.) using `StandardScaler()` from sklearn.\n",
    "\n",
    "After processing, display the first 5 rows of your cleaned and transformed dataset to verify results.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "df_encoded = pd.get_dummies(df, columns=['your-categorical-columns'])\n",
    "scaler = StandardScaler()\n",
    "df_encoded[your_numerical_columns] = scaler.fit_transform(df_encoded[your_numerical_columns])\n",
    "df_encoded.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3df28",
   "metadata": {},
   "source": [
    "\n",
    "## üõ†Ô∏è Step 6: Implement PCA Manually\n",
    "\n",
    "Gain deeper insight by manually implementing PCA. Create a function called `perform_pca()` that:\n",
    "\n",
    "- Accepts normalized data and the number of principal components (`n_components`) as arguments.\n",
    "- Calculates covariance matrix, eigenvalues, and eigenvectors.\n",
    "- Sorts eigenvectors based on eigenvalues and selects top components.\n",
    "- Projects data onto the selected components to reduce dimensionality.\n",
    "\n",
    "Execute PCA for 2 components and verify by displaying the top 5 rows of the result.\n",
    "\n",
    "**Structure your function as follows:**\n",
    "\n",
    "```python\n",
    "def perform_pca(data, n_components=2):\n",
    "    # Your PCA code here\n",
    "    return pca_result\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e04c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_pca(data, n_components=2):\n",
    "    # Implement PCA steps here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85842f7",
   "metadata": {},
   "source": [
    "\n",
    "## üìà Step 7: Visualizing and Interpreting PCA Results\n",
    "\n",
    "Now, visualize the PCA output clearly:\n",
    "\n",
    "- **Scatter plot:** Plot the two principal components to visualize data separation and clusters.\n",
    "- **Heatmap:** Illustrate correlations between original features and PCA components using a heatmap.\n",
    "- Provide a brief interpretation of what each principal component represents in terms of original features.\n",
    "\n",
    "**Visualization Tools:**\n",
    "\n",
    "- Use `plt.scatter()` for scatter plots.\n",
    "- Use `sns.heatmap()` for correlation heatmaps.\n",
    "\n",
    "Reflect on your findings briefly in your analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6fe548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2e80a",
   "metadata": {},
   "source": [
    "\n",
    "## üìâ Step 8: PCA Explained Variance\n",
    "\n",
    "Determine how many principal components are needed by plotting the cumulative explained variance.\n",
    "\n",
    "**Tasks:**\n",
    "- Fit PCA from `sklearn.decomposition` to your encoded data.\n",
    "- Plot the cumulative sum of the explained variance ratio.\n",
    "\n",
    "**Hint:**  \n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(your_data)\n",
    "# plot cumulative explained variance here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184806ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0fb25",
   "metadata": {},
   "source": [
    "\n",
    "## üåÄ Step 9: K-means Clustering on PCA results\n",
    "\n",
    "Apply K-means clustering (with 2 clusters) on your PCA-transformed data and visualize the clusters.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "- Apply `KMeans` clustering from `sklearn.cluster`.\n",
    "- Visualize clusters using scatter plots and mark cluster centers.\n",
    "\n",
    "**Hint:**\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "# apply KMeans on PCA data\n",
    "# visualize your clusters clearly\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c9536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424e18e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "*Project designed by: Amirerfan Teimoori*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
